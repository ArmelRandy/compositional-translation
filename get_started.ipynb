{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd compositional-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comptra.sampler import cohereSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to initialize backend 'cuda': \n",
      "Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from comptra.retriever import Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building index from IDs objects                       \n",
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "retriever = Retriever(\n",
    "    dataset_name_or_path=\"flores\",\n",
    "    retriever_type=\"bm25s\",\n",
    "    source_language=\"English\",\n",
    "    target_language=\"French\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use an instruction fine-tuned model!\n",
      "We are going to use NLLB, precisely facebook/nllb-200-distilled-600M\n",
      "Merge algorithm: vanilla, selection method: comet-qe\n"
     ]
    }
   ],
   "source": [
    "sampler = cohereSampler(\n",
    "    model_name_or_path=\"command-r-08-2024\",\n",
    "    tokenizer_name_or_path=None,\n",
    "    src=\"English\",\n",
    "    tgt=\"French\",\n",
    "    template=None,\n",
    "    merge_prompt=\"vanilla\",\n",
    "    # method_translate=\"vanilla\",\n",
    "    method_translate=\"nllb\",\n",
    "    selection_method=\"comet-qe\",\n",
    "    nllb_name_or_path=\"facebook/nllb-200-distilled-600M\",\n",
    "    method_divide=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "sentence = \"I am very inclined towards eating your pancreas to alleviate my hunger.\"\n",
    "t = sampler.translate(\n",
    "    sentences=[sentence], temperature=0.0, num_return_sequences=1, do_sample=False\n",
    ")\n",
    "print(f\"NLLB: {t[0]}\")\n",
    "dico[\"NLLB\"] = t[0]\n",
    "#\"\"\"\n",
    "outputs = sampler.generate(\n",
    "    prompts=[\n",
    "        f\"What is the French translation of the following sentence\\n\\n{sentence}\"\n",
    "    ],\n",
    "    max_new_tokens=100,\n",
    "    top_p=1.0,\n",
    "    temperature=0,\n",
    ")\n",
    "print(f\"\\n---zero-shot MT\\n---: {outputs[0]}\")\n",
    "outputs = sampler.refine([sentence], [outputs[0]], 1)\n",
    "dico[\"ZS\"] = outputs[0]\n",
    "print(f\"\\n---zero-shot MT + Refine\\n---: {outputs[0]}\")\n",
    "dico[\"ZSREFINE\"] = outputs[0]\n",
    "outputs = sampler.cot(\n",
    "    prompts=[\n",
    "        f\"What is the French translation of the following sentence\\n\\n{sentence}\\n\\nLet's think step by step.\"\n",
    "    ],\n",
    "    sentences=[sentence],\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "print(f\"zero-shot CoT MT: {outputs[0]}\")\n",
    "dico[\"ZSCoT\"] = outputs[0]\n",
    "\n",
    "outputs = sampler.maps(sentences=[sentence], max_new_tokens=500)\n",
    "print(f\"MAPS MT: {outputs[0]}\")\n",
    "dico[\"MAPS\"] = outputs[0]\n",
    "\n",
    "outputs = sampler.step_by_step(sentences=[sentence], max_new_tokens=500)\n",
    "print(f\"SBYS: {outputs[0]}\")\n",
    "dico[\"SBYS\"] = outputs[0]\n",
    "\n",
    "demonstrations = retriever.query(\n",
    "    sentence, 5\n",
    ")\n",
    "\n",
    "outputs = sampler.tear(sentences=[sentence], demonstrations=[demonstrations], max_new_tokens=500)\n",
    "print(f\"TEaR: {outputs[0]}\")\n",
    "dico[\"TEaR\"] = outputs[0]\n",
    "# CompTra\n",
    "sentences = [sentence]\n",
    "subsentences = sampler.divide(n_splits=-1, sentences=sentences)\n",
    "print(subsentences)\n",
    "translations = []\n",
    "for i in range(len(subsentences)):\n",
    "    t = sampler.translate(\n",
    "        sentences=subsentences[i],\n",
    "        demonstrations=[[] for _ in range(len(subsentences[i]))],\n",
    "    )\n",
    "    translations.append(t)\n",
    "print(translations)\n",
    "comptra_translations = sampler.merge(\n",
    "    sentences=sentences,\n",
    "    inputs=subsentences,\n",
    "    outputs=translations,\n",
    "    max_new_tokens=300,\n",
    ")\n",
    "print(f\"CompTra translation: {comptra_translations[0]}\")\n",
    "dico[\"CompTra\"] = comptra_translations[0]\n",
    "refine_translations = sampler.refine(\n",
    "    sentences = sentences,\n",
    "    prev_translations = comptra_translations,\n",
    "    number_of_refining_steps = 1\n",
    ")\n",
    "dico[\"CompTra + Refine\"] = refine_translations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLB: Je suis très enclin à manger votre pancréas pour soulager ma faim.\n",
      "ZS: \"Je suis fortement tenté de manger votre pancréas pour apaiser ma faim.\"\n",
      "ZSREFINE: \"Je suis fortement tenté de manger votre pancréas pour apaiser ma faim.\"\n",
      "ZSCoT: Je suis très enclin à manger votre pancréas pour soulager ma faim.\n",
      "MAPS: Je suis très enclin à manger ton pancréas pour apaiser ma faim.\n",
      "SBYS: \"Je suis fortement tenté de manger votre pancréas pour apaiser ma faim.\"\n",
      "TEaR: Je suis très tenté de manger votre pancréas pour apaiser ma faim.\n",
      "CompTra: Je suis très enclin à manger votre pancréas pour apaiser ma faim.\n",
      "CompTra + Refine: Je suis fortement tenté de manger votre pancréas pour apaiser ma faim.\n"
     ]
    }
   ],
   "source": [
    "for key in dico:\n",
    "    print(f\"{key}: {dico[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
